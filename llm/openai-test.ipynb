{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Testing OpenAI API Inference</h1>\n",
    "This notebook uses the Watchman dataset data. It runs inference using OpenAI service APIs.</br>\n",
    "This notebook will randomly pick a couple of positive and negative samples to run inference using</br>\n",
    "\"openai-generic\" Watchman's model_interfaces.py's model interface. You'll need an OpenAI API account</br>\n",
    "and API key. The key is expected to be found in the OPENAI_API_KEY variable in your .env file.</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import base64\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's confirm that APIs are working.\n",
    "# Get the API key from the .env file\n",
    "parent_dir = os.path.curdir + '/..'\n",
    "env_path = os.path.join(parent_dir, '.env')\n",
    "load_dotenv(env_path)\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "if openai_api_key:\n",
    "    print(\"OPENAI_API_KEY has been loaded successfully.\")\n",
    "else:\n",
    "    print(f\"OPENAI_API_KEY not found in the {env_path} file.\")\n",
    "\n",
    "client = OpenAI(\n",
    "    # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
    "    api_key=openai_api_key,\n",
    ")\n",
    "models = client.models.list()\n",
    "\n",
    "print(f\"Served models:\")\n",
    "target_model = 'o4-mini' # this one is reasoning, requires a lot of output tokens\n",
    "#target_model = 'gpt-4o-mini' # faster and no reasoning, but dummer, descriptions are much worse than o4-mini\n",
    "openai_model = None\n",
    "for m in models:\n",
    "    print(f\"  {m.id}\")\n",
    "    if m.id == target_model:\n",
    "        openai_model = m.id\n",
    "if openai_model:\n",
    "    print(f\"Will use: {openai_model}\")\n",
    "else:\n",
    "    print(f\"No model: {target_model}\")\n",
    "\n",
    "client = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model interfaces we can use for testing\n",
    "print(f\"Working dir: {os.getcwd()}\")\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "sys.path.append(os.path.abspath(\"../orchestrator\"))\n",
    "from shared_settings import *\n",
    "from model_interfaces import *\n",
    "print(MODELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up vars for finding train data\n",
    "dataset = \"../.data/dataset\" # dataset folder location\n",
    "chans = [\"porch\"] # list of channels to load the data for\n",
    "objs = [\"person\"] # list of objects to load the data for\n",
    "model_name = \"openai-generic\" # model interface name to use for inference experimentation\n",
    "c_desc = {\n",
    "    \"porch\": \"Porch\",\n",
    "}\n",
    "o_desc = {\n",
    "    \"person\": \"a person\",\n",
    "}\n",
    "MODEL_INTERFACE = MODELS[model_name](model_to_use=openai_model, api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run test inference\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "import base64\n",
    "import random\n",
    "\n",
    "def test_inf(s, c, o, res):\n",
    "    print(f\"Subdir: {s} Expecting: {res}\")\n",
    "    image_pname = f\"{s}/image.jpg\"\n",
    "    img_data = base64.b64encode(Path(image_pname).read_bytes()).decode()\n",
    "    res, msg = MODEL_INTERFACE.locate(img_data, o_desc[o], c_desc[c])\n",
    "    img = Image.open(image_pname)\n",
    "    w, h = img.size\n",
    "    display(img.resize((int(w / 4), int(h / 4))))\n",
    "    print(\"Inference result: \", \"yes\" if res else \"no\")\n",
    "    print(\"Location: \", msg if msg is not None else \"N/A\")\n",
    "    print(\"---------------------------\")\n",
    "\n",
    "for c in chans:\n",
    "    for o in objs:\n",
    "        dir = f\"{dataset}/{c}/{o}\"\n",
    "        subdirs = [f.path for f in os.scandir(dir) if f.is_dir()]\n",
    "        true_pos = False\n",
    "        false_pos = False\n",
    "        random.shuffle(subdirs)\n",
    "        for s in subdirs:\n",
    "            if true_pos and false_pos:\n",
    "                break\n",
    "            if os.path.exists(f\"{s}/skip\"):\n",
    "                continue\n",
    "            if not false_pos and os.path.exists(f\"{s}/no\"):\n",
    "                test_inf(s, c, o, \"no\")\n",
    "                false_pos = True\n",
    "            if not true_pos and not os.path.exists(f\"{s}/no\"):\n",
    "                test_inf(s, c, o, \"yes\")\n",
    "                true_pos = True\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
